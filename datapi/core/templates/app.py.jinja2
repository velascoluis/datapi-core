import sys
import asyncio
import time
import socket
from urllib.parse import urlparse

# Prevent uvloop from being imported
sys.modules['uvloop'] = None

# Ensure we're using the default event loop policy
asyncio.set_event_loop_policy(asyncio.DefaultEventLoopPolicy())

# Prevent IPython from being imported
sys.modules['IPython'] = None

import json
import numpy as np
import logging
from fastapi import FastAPI
from pyiceberg.catalog.rest import RestCatalog
from datapi.core.utils import run_malloy_query
import os
from fastapi.responses import JSONResponse
import weakref
import pandas as pd
import httpx
import duckdb

from fastapi import FastAPI
from fastapi.openapi.docs import get_swagger_ui_html
from fastapi.openapi.utils import get_openapi

class CustomJSONEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, pd.DataFrame):
            return obj.to_dict(orient='records')
        elif isinstance(obj, pd.Series):
            return obj.to_dict()
        elif isinstance(obj, weakref.ReferenceType):
            return None  # or some other placeholder value
        else:
            return super().default(obj)

app = FastAPI(docs_url=None, redoc_url=None, openapi_url=None)

def _get_pyiceberg_catalog(polaris_uri,credentials,catalog_name):
    return RestCatalog(
        name="polaris",
        uri=polaris_uri,
        warehouse=catalog_name,
        credential=credentials,
        scope="PRINCIPAL_ROLE:ALL",
    )

async def fetch_resource_data(resource_url, max_retries=3):
    parsed_url = urlparse(resource_url)
    logging.info(f"Attempting to resolve {parsed_url.hostname}")
    try:
        ip_address = socket.gethostbyname(parsed_url.hostname)
        logging.info(f"Resolved {parsed_url.hostname} to {ip_address}")
    except socket.gaierror as e:
        logging.error(f"Failed to resolve {parsed_url.hostname}: {e}")
        raise

    for attempt in range(max_retries):
        try:
            start_time = time.time()
            async with httpx.AsyncClient(timeout=30.0) as client:
                logging.info(f"Sending request to {resource_url}/get_data")
                response = await client.get(f"{resource_url}/get_data")
                response.raise_for_status()
                end_time = time.time()
                logging.info(f"Request completed in {end_time - start_time:.2f} seconds")
                return response.json()
        except httpx.TimeoutException:
            logging.warning(f"Timeout on attempt {attempt + 1} for {resource_url}")
            if attempt == max_retries - 1:
                logging.error(f"Max retries reached for {resource_url}")
                raise
        except httpx.HTTPStatusError as e:
            logging.error(f"HTTP error occurred on attempt {attempt + 1}: {e}")
            if attempt == max_retries - 1:
                raise
        except Exception as e:
            logging.error(f"Unexpected error on attempt {attempt + 1}: {e}")
            if attempt == max_retries - 1:
                raise
        await asyncio.sleep(2 ** attempt)  # Exponential backoff

@app.get("/get_data")
async def get_data():
    catalog = _get_pyiceberg_catalog(
        polaris_uri="{{ polaris_uri }}",
        credentials="{{ credentials }}",
        catalog_name="{{ catalog_name }}"
    )
    source = """{{ source }}"""
    query = """{{ query }}"""

    {% if depends_on_type == "table" %}
    table = catalog.load_table("{{ namespace_name }}.{{ table_name }}")
    con = table.scan().to_duckdb(table_name="{{ table_name }}")
    {% elif depends_on_type == "resource" %}
    # For resource dependency, first fetch data from the dependent resource
    resource_data = await fetch_resource_data("{{ depends_on_resource }}")
    
    # Create a temporary DuckDB database in memory
    con = duckdb.connect(":memory:")
    
    # Convert the JSON data to a pandas DataFrame and then to a DuckDB table
    df = pd.DataFrame(resource_data)
    con.register("resource_data", df)
    {% endif %}

    result = await run_malloy_query(con, source, query)
    try:
        if isinstance(result, pd.DataFrame):
            json_result = json.dumps(result.to_dict(orient='records'), cls=CustomJSONEncoder)
        else:
            json_result = json.dumps(result, cls=CustomJSONEncoder)
        return JSONResponse(content=json.loads(json_result))
    except Exception as e:
        logging.error(f"Serialization failed: {str(e)}")
        return JSONResponse(content={"error": f"Serialization failed: {str(e)}"}, status_code=500)
    

@app.get("/docs", include_in_schema=False)
async def custom_swagger_ui_html():
    return get_swagger_ui_html(
        openapi_url="/openapi.json",
        title="API Docs",
        oauth2_redirect_url="/docs/oauth2-redirect",
        swagger_js_url="https://unpkg.com/swagger-ui-dist@4/swagger-ui-bundle.js",
        swagger_css_url="https://unpkg.com/swagger-ui-dist@4/swagger-ui.css",
    )

@app.get("/openapi.json", include_in_schema=False)
async def get_open_api_endpoint():
    openapi_schema = get_openapi(
        title="FastAPI",
        version="1.0.0",
        description="API documentation for the DataAPI",
        routes=app.routes,
    )
    openapi_schema["openapi"] = "3.0.2"
    return openapi_schema

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8080))
    uvicorn.run(app, host="0.0.0.0", port=port)